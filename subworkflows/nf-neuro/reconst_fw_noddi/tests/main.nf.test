nextflow_workflow {
    name "Test Subworkflow RECONST_FW_NODDI"
    script "../main.nf"
    workflow "RECONST_FW_NODDI"

    tag "subworkflows"
    tag "subworkflows_nfneuro"
    tag "subworkflows/reconst_fw_noddi"

    tag "load_test_data"
    tag "reconst/noddi"
    tag "reconst/freewater"
    tag "reconst/diffusivitypriors"
    tag "reconst/meandiffusivitypriors"
    tag "reconst/dtimetrics"

    tag "stub"
    options "-stub-run"

    setup {
        run("LOAD_TEST_DATA", alias: "LOAD_DATA") {
            script "../../load_test_data/main.nf"
            process {
                """
                input[0] = Channel.from( [ "processing.zip", "commit_amico.zip" ] )
                input[1] = "test.load-test-data"
                """
            }
        }
    }

    test("reconst_fw_noddi - noddi") {
        when {
            workflow {
                """
                ch_split_test_data = LOAD_DATA.out.test_data_directory
                    .branch{
                        processing: it.simpleName == "processing"
                        commit_amico: it.simpleName == "commit_amico"
                    }

                input[0] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/dwi.nii.gz"),
                    file("\${test_data_directory}/dwi.bval"),
                    file("\${test_data_directory}/dwi.bvec")
                    ]}
                input[1] = ch_split_test_data.commit_amico
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/mask.nii.gz")
                    ]}
                input[2] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                        [ id:'test', single_end:false ], // meta map
                        file("\${test_data_directory}/fa.nii.gz"),
                        file("\${test_data_directory}/ad.nii.gz"),
                        file("\${test_data_directory}/rd.nii.gz"),
                        file("\${test_data_directory}/md.nii.gz")
                    ]}
                input[3] = true  // run_noddi
                input[4] = false // run_freewater
                input[5] = null  // para_diff
                input[6] = null  // iso_diff
                input[7] = null  // perp_diff_min
                input[8] = null  // perp_diff_max
                input[9] = false // average_diff_priors
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success},
                { assert snapshot(
                    workflow.out
                        .findAll{ channel -> !channel.key.isInteger() && channel.value  }
                        .collectEntries{ channel ->
                            [(channel.key): ["versions"].contains(channel.key)
                                ? channel.value
                                : channel.value.collect{ subject ->
                                    [ subject[0] ] + subject[1..-1].collect{ entry -> entry ? file(entry).name : "" }
                            } ]
                        }
                ).match() },
                { assert workflow.out
                    .findAll{ !it.key.isInteger() }
                    .every{ channel ->
                        channel.value.every{ subject -> subject instanceof ArrayList
                            ? subject.every()
                            : subject } } }
            )
        }
    }

    test("reconst_fw_noddi - freewater") {
        when {
            workflow {
                """
                ch_split_test_data = LOAD_DATA.out.test_data_directory
                    .branch{
                        processing: it.simpleName == "processing"
                        commit_amico: it.simpleName == "commit_amico"
                    }

                input[0] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/dwi.nii.gz"),
                    file("\${test_data_directory}/dwi.bval"),
                    file("\${test_data_directory}/dwi.bvec")
                    ]}
                input[1] = ch_split_test_data.commit_amico
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/mask.nii.gz")
                    ]}
                input[2] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                        [ id:'test', single_end:false ], // meta map
                        file("\${test_data_directory}/fa.nii.gz"),
                        file("\${test_data_directory}/ad.nii.gz"),
                        file("\${test_data_directory}/rd.nii.gz"),
                        file("\${test_data_directory}/md.nii.gz")
                    ]}
                input[3] = false // run_noddi
                input[4] = true  // run_freewater
                input[5] = null  // para_diff
                input[6] = null  // iso_diff
                input[7] = null  // perp_diff_min
                input[8] = null  // perp_diff_max
                input[9] = false // average_diff_priors
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success},
                { assert snapshot(
                    workflow.out
                        .findAll{ channel -> !channel.key.isInteger() && channel.value  }
                        .collectEntries{ channel ->
                            [(channel.key): ["versions"].contains(channel.key)
                                ? channel.value
                                : channel.value.collect{ subject ->
                                    [ subject[0] ] + subject[1..-1].collect{ entry -> entry ? file(entry).name : "" }
                            } ]
                        }
                ).match() },
                { assert workflow.out
                    .findAll{ !it.key.isInteger() }
                    .every{ channel ->
                        channel.value.every{ subject -> subject instanceof ArrayList
                            ? subject.every()
                            : subject } } }
            )
        }
    }

    test("reconst_fw_noddi - noddi & freewater") {
        when {
            workflow {
                """
                ch_split_test_data = LOAD_DATA.out.test_data_directory
                    .branch{
                        processing: it.simpleName == "processing"
                        commit_amico: it.simpleName == "commit_amico"
                    }

                input[0] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/dwi.nii.gz"),
                    file("\${test_data_directory}/dwi.bval"),
                    file("\${test_data_directory}/dwi.bvec")
                    ]}
                input[1] = ch_split_test_data.commit_amico
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/mask.nii.gz")
                    ]}
                input[2] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                        [ id:'test', single_end:false ], // meta map
                        file("\${test_data_directory}/fa.nii.gz"),
                        file("\${test_data_directory}/ad.nii.gz"),
                        file("\${test_data_directory}/rd.nii.gz"),
                        file("\${test_data_directory}/md.nii.gz")
                    ]}
                input[3] = true  // run_noddi
                input[4] = true  // run_freewater
                input[5] = null  // para_diff
                input[6] = null  // iso_diff
                input[7] = null  // perp_diff_min
                input[8] = null  // perp_diff_max
                input[9] = false // average_diff_priors
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success},
                { assert snapshot(
                    workflow.out
                        .findAll{ channel -> !channel.key.isInteger() && channel.value  }
                        .collectEntries{ channel ->
                            [(channel.key): ["versions"].contains(channel.key)
                                ? channel.value
                                : channel.value.collect{ subject ->
                                    [ subject[0] ] + subject[1..-1].collect{ entry -> entry ? file(entry).name : "" }
                            } ]
                        }
                ).match() },
                { assert workflow.out
                    .findAll{ !it.key.isInteger() }
                    .every{ channel ->
                        channel.value.every{ subject -> subject instanceof ArrayList
                            ? subject.every()
                            : subject } } }
            )
        }
    }

    test("reconst_fw_noddi - noddi & freewater - average priors") {
        when {
            workflow {
                """
                ch_split_test_data = LOAD_DATA.out.test_data_directory
                    .branch{
                        processing: it.simpleName == "processing"
                        commit_amico: it.simpleName == "commit_amico"
                    }

                input[0] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/dwi.nii.gz"),
                    file("\${test_data_directory}/dwi.bval"),
                    file("\${test_data_directory}/dwi.bvec")
                    ]}
                input[1] = ch_split_test_data.commit_amico
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/mask.nii.gz")
                    ]}
                input[2] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                        [ id:'test', single_end:false ], // meta map
                        file("\${test_data_directory}/fa.nii.gz"),
                        file("\${test_data_directory}/ad.nii.gz"),
                        file("\${test_data_directory}/rd.nii.gz"),
                        file("\${test_data_directory}/md.nii.gz")
                    ]}
                input[3] = true  // run_noddi
                input[4] = true  // run_freewater
                input[5] = null  // para_diff
                input[6] = null  // iso_diff
                input[7] = null  // perp_diff_min
                input[8] = null  // perp_diff_max
                input[9] = true  // average_diff_priors
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success},
                { assert snapshot(
                    workflow.out
                        .findAll{ channel -> !channel.key.isInteger() && channel.value  }
                        .collectEntries{ channel ->
                            [(channel.key): ["versions"].contains(channel.key)
                                ? channel.value
                                : channel.value.collect{ subject ->
                                    [ subject[0] ] + subject[1..-1].collect{ entry -> entry ? file(entry).name : "" }
                            } ]
                        }
                ).match() },
                { assert workflow.out
                    .findAll{ !it.key.isInteger() }
                    .every{ channel ->
                        channel.value.every{ subject -> subject instanceof ArrayList
                            ? subject.every()
                            : subject } } }
            )
        }
    }

    test("reconst_fw_noddi - noddi & freewater - custom priors") {
        when {
            workflow {
                """
                ch_split_test_data = LOAD_DATA.out.test_data_directory
                    .branch{
                        processing: it.simpleName == "processing"
                        commit_amico: it.simpleName == "commit_amico"
                    }

                input[0] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/dwi.nii.gz"),
                    file("\${test_data_directory}/dwi.bval"),
                    file("\${test_data_directory}/dwi.bvec")
                    ]}
                input[1] = ch_split_test_data.commit_amico
                    .map{ test_data_directory -> [
                    [ id:'test', single_end:false ], // meta map
                    file("\${test_data_directory}/mask.nii.gz")
                    ]}
                input[2] = ch_split_test_data.processing
                    .map{ test_data_directory -> [
                        [ id:'test', single_end:false ], // meta map
                        file("\${test_data_directory}/fa.nii.gz"),
                        file("\${test_data_directory}/ad.nii.gz"),
                        file("\${test_data_directory}/rd.nii.gz"),
                        file("\${test_data_directory}/md.nii.gz")
                    ]}
                input[3] = true    // run_noddi
                input[4] = true    // run_freewater
                input[5] = 0.0015  // para_diff
                input[6] = 0.003   // iso_diff
                input[7] = 0.0001  // perp_diff_min
                input[8] = 0.0007  // perp_diff_max
                input[9] = true    // average_diff_priors
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success},
                { assert snapshot(
                    workflow.out
                        .findAll{ channel -> !channel.key.isInteger() && channel.value  }
                        .collectEntries{ channel ->
                            [(channel.key): ["versions"].contains(channel.key)
                                ? channel.value
                                : channel.value.collect{ subject ->
                                    [ subject[0] ] + subject[1..-1].collect{ entry -> entry ? file(entry).name : "" }
                            } ]
                        }
                ).match() },
                { assert workflow.out
                    .findAll{ !it.key.isInteger() }
                    .every{ channel ->
                        channel.value.every{ subject -> subject instanceof ArrayList
                            ? subject.every()
                            : subject } } }
            )
        }
    }
}
